^C(colon) chan@chan-desktop:~/Desktop/DLD1$ python train.py --model unet
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]             640
       BatchNorm2d-2         [-1, 64, 256, 256]             128
              ReLU-3         [-1, 64, 256, 256]               0
            Conv2d-4         [-1, 64, 256, 256]          36,928
       BatchNorm2d-5         [-1, 64, 256, 256]             128
              ReLU-6         [-1, 64, 256, 256]               0
         MaxPool2d-7         [-1, 64, 128, 128]               0
            Conv2d-8        [-1, 128, 128, 128]          73,856
       BatchNorm2d-9        [-1, 128, 128, 128]             256
             ReLU-10        [-1, 128, 128, 128]               0
           Conv2d-11        [-1, 128, 128, 128]         147,584
      BatchNorm2d-12        [-1, 128, 128, 128]             256
             ReLU-13        [-1, 128, 128, 128]               0
        MaxPool2d-14          [-1, 128, 64, 64]               0
           Conv2d-15          [-1, 256, 64, 64]         295,168
      BatchNorm2d-16          [-1, 256, 64, 64]             512
             ReLU-17          [-1, 256, 64, 64]               0
           Conv2d-18          [-1, 256, 64, 64]         590,080
      BatchNorm2d-19          [-1, 256, 64, 64]             512
             ReLU-20          [-1, 256, 64, 64]               0
        MaxPool2d-21          [-1, 256, 32, 32]               0
           Conv2d-22          [-1, 512, 32, 32]       1,180,160
      BatchNorm2d-23          [-1, 512, 32, 32]           1,024
             ReLU-24          [-1, 512, 32, 32]               0
           Conv2d-25          [-1, 512, 32, 32]       2,359,808
      BatchNorm2d-26          [-1, 512, 32, 32]           1,024
             ReLU-27          [-1, 512, 32, 32]               0
        MaxPool2d-28          [-1, 512, 16, 16]               0
           Conv2d-29         [-1, 1024, 16, 16]       4,719,616
      BatchNorm2d-30         [-1, 1024, 16, 16]           2,048
             ReLU-31         [-1, 1024, 16, 16]               0
           Conv2d-32         [-1, 1024, 16, 16]       9,438,208
      BatchNorm2d-33         [-1, 1024, 16, 16]           2,048
             ReLU-34         [-1, 1024, 16, 16]               0
         Upsample-35         [-1, 1024, 32, 32]               0
           Conv2d-36          [-1, 512, 32, 32]       7,078,400
             ReLU-37          [-1, 512, 32, 32]               0
           Conv2d-38          [-1, 512, 32, 32]       2,359,808
             ReLU-39          [-1, 512, 32, 32]               0
         Upsample-40          [-1, 512, 64, 64]               0
           Conv2d-41          [-1, 256, 64, 64]       1,769,728
             ReLU-42          [-1, 256, 64, 64]               0
           Conv2d-43          [-1, 256, 64, 64]         590,080
             ReLU-44          [-1, 256, 64, 64]               0
         Upsample-45        [-1, 256, 128, 128]               0
           Conv2d-46        [-1, 128, 128, 128]         442,496
             ReLU-47        [-1, 128, 128, 128]               0
           Conv2d-48        [-1, 128, 128, 128]         147,584
             ReLU-49        [-1, 128, 128, 128]               0
         Upsample-50        [-1, 128, 256, 256]               0
           Conv2d-51         [-1, 64, 256, 256]         110,656
             ReLU-52         [-1, 64, 256, 256]               0
           Conv2d-53         [-1, 64, 256, 256]          36,928
             ReLU-54         [-1, 64, 256, 256]               0
           Conv2d-55          [-1, 1, 256, 256]              65
================================================================
Total params: 31,385,729
Trainable params: 31,385,729
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.25
Forward/backward pass size (MB): 747.50
Params size (MB): 119.73
Estimated Total Size (MB): 867.48
----------------------------------------------------------------
----------------------------------------------------------------
The number of train set: 10924
The number of valid set: 1214
----------------------------------------------------------------
Epoch 1/200
----------
LR 0.001
train: bce: 0.038903, dice_loss: 0.308647, loss: 0.347550
val: bce: 0.011747, dice_loss: 0.095078, loss: 0.106825
Validation loss decreased (inf --> 0.106825).  Saving best model ...
6m 38s
Epoch 2/200
----------
LR 0.001
train: bce: 0.012137, dice_loss: 0.095354, loss: 0.107491
val: bce: 0.011616, dice_loss: 0.095137, loss: 0.106753
Validation loss decreased (0.106825 --> 0.106753).  Saving best model ...
6m 35s
Epoch 3/200
----------
LR 0.001
train: bce: 0.012077, dice_loss: 0.095360, loss: 0.107437
val: bce: 0.011509, dice_loss: 0.095186, loss: 0.106695
Validation loss decreased (0.106753 --> 0.106695).  Saving best model ...
6m 28s
Epoch 4/200
----------
LR 0.001
train: bce: 0.012019, dice_loss: 0.095364, loss: 0.107383
val: bce: 0.011739, dice_loss: 0.094854, loss: 0.106593
Validation loss decreased (0.106695 --> 0.106593).  Saving best model ...
6m 27s
Epoch 5/200
----------
LR 0.001
train: bce: 0.011997, dice_loss: 0.095350, loss: 0.107347
val: bce: 0.011406, dice_loss: 0.095182, loss: 0.106588
Validation loss decreased (0.106593 --> 0.106588).  Saving best model ...
6m 28s
Epoch 6/200
----------
LR 0.001
train: bce: 0.011945, dice_loss: 0.095373, loss: 0.107318
val: bce: 0.011804, dice_loss: 0.094770, loss: 0.106574
Validation loss decreased (0.106588 --> 0.106574).  Saving best model ...
6m 28s
Epoch 7/200
----------
LR 0.001
train: bce: 0.011933, dice_loss: 0.095357, loss: 0.107291
val: bce: 0.011409, dice_loss: 0.095125, loss: 0.106534
Validation loss decreased (0.106574 --> 0.106534).  Saving best model ...
6m 28s
Epoch 8/200
----------
LR 0.001
train: bce: 0.011907, dice_loss: 0.095361, loss: 0.107268
val: bce: 0.011721, dice_loss: 0.094782, loss: 0.106502
Validation loss decreased (0.106534 --> 0.106502).  Saving best model ...
6m 28s
Epoch 9/200
----------
LR 0.001
train: bce: 0.011893, dice_loss: 0.095357, loss: 0.107251
val: bce: 0.011879, dice_loss: 0.094658, loss: 0.106537
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 10/200
----------
LR 0.001
train: bce: 0.011872, dice_loss: 0.095359, loss: 0.107230
val: bce: 0.011674, dice_loss: 0.094783, loss: 0.106458
Validation loss decreased (0.106502 --> 0.106458).  Saving best model ...
6m 28s
Epoch 11/200
----------
LR 0.001
train: bce: 0.011870, dice_loss: 0.095345, loss: 0.107215
val: bce: 0.011242, dice_loss: 0.095237, loss: 0.106479
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 12/200
----------
LR 0.001
train: bce: 0.011812, dice_loss: 0.095364, loss: 0.107176
val: bce: 0.011346, dice_loss: 0.095039, loss: 0.106385
Validation loss decreased (0.106458 --> 0.106385).  Saving best model ...
6m 28s
Epoch 13/200
----------
LR 0.001
train: bce: 0.011820, dice_loss: 0.095349, loss: 0.107168
val: bce: 0.010866, dice_loss: 0.095864, loss: 0.106730
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 14/200
----------
LR 0.001
train: bce: 0.011773, dice_loss: 0.095358, loss: 0.107131
val: bce: 0.011635, dice_loss: 0.094749, loss: 0.106384
Validation loss decreased (0.106385 --> 0.106384).  Saving best model ...
6m 29s
Epoch 15/200
----------
LR 0.001
train: bce: 0.011766, dice_loss: 0.095347, loss: 0.107113
val: bce: 0.011505, dice_loss: 0.094806, loss: 0.106311
Validation loss decreased (0.106384 --> 0.106311).  Saving best model ...
6m 31s
Epoch 16/200
----------
LR 0.001
train: bce: 0.011727, dice_loss: 0.095355, loss: 0.107083
val: bce: 0.011302, dice_loss: 0.094974, loss: 0.106276
Validation loss decreased (0.106311 --> 0.106276).  Saving best model ...
6m 28s
Epoch 17/200
----------
LR 0.001
train: bce: 0.011697, dice_loss: 0.095351, loss: 0.107048
val: bce: 0.011354, dice_loss: 0.094878, loss: 0.106231
Validation loss decreased (0.106276 --> 0.106231).  Saving best model ...
6m 28s
Epoch 18/200
----------
LR 0.001
train: bce: 0.011618, dice_loss: 0.095350, loss: 0.106968
val: bce: 0.011467, dice_loss: 0.094761, loss: 0.106228
Validation loss decreased (0.106231 --> 0.106228).  Saving best model ...
6m 28s
Epoch 19/200
----------
LR 0.001
train: bce: 0.011603, dice_loss: 0.095344, loss: 0.106947
val: bce: 0.011118, dice_loss: 0.095029, loss: 0.106146
Validation loss decreased (0.106228 --> 0.106146).  Saving best model ...
6m 28s
Epoch 20/200
----------
LR 0.001
train: bce: 0.011529, dice_loss: 0.095345, loss: 0.106874
val: bce: 0.010888, dice_loss: 0.095220, loss: 0.106108
Validation loss decreased (0.106146 --> 0.106108).  Saving best model ...
6m 31s
Epoch 21/200
----------
LR 0.001
train: bce: 0.011430, dice_loss: 0.095342, loss: 0.106772
val: bce: 0.010886, dice_loss: 0.095171, loss: 0.106057
Validation loss decreased (0.106108 --> 0.106057).  Saving best model ...
6m 40s
Epoch 22/200
----------
LR 0.001
train: bce: 0.011415, dice_loss: 0.095340, loss: 0.106756
val: bce: 0.011040, dice_loss: 0.094922, loss: 0.105962
Validation loss decreased (0.106057 --> 0.105962).  Saving best model ...
6m 29s
Epoch 23/200
----------
LR 0.001
train: bce: 0.011302, dice_loss: 0.095352, loss: 0.106653
val: bce: 0.011096, dice_loss: 0.094783, loss: 0.105879
Validation loss decreased (0.105962 --> 0.105879).  Saving best model ...
6m 28s
Epoch 24/200
----------
LR 0.001
train: bce: 0.011215, dice_loss: 0.095337, loss: 0.106552
val: bce: 0.010440, dice_loss: 0.095658, loss: 0.106098
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 25/200
----------
LR 0.001
train: bce: 0.011141, dice_loss: 0.095347, loss: 0.106487
val: bce: 0.010834, dice_loss: 0.094905, loss: 0.105739
Validation loss decreased (0.105879 --> 0.105739).  Saving best model ...
6m 33s
Epoch 26/200
----------
LR 0.001
train: bce: 0.011106, dice_loss: 0.095344, loss: 0.106449
val: bce: 0.010251, dice_loss: 0.095634, loss: 0.105884
EarlyStopping counter: 1 out of 30
6m 37s
Epoch 27/200
----------
LR 0.001
train: bce: 0.011026, dice_loss: 0.095354, loss: 0.106379
val: bce: 0.010694, dice_loss: 0.094951, loss: 0.105645
Validation loss decreased (0.105739 --> 0.105645).  Saving best model ...
6m 41s
Epoch 28/200
----------
LR 0.001
train: bce: 0.010894, dice_loss: 0.095344, loss: 0.106239
val: bce: 0.010662, dice_loss: 0.094898, loss: 0.105559
Validation loss decreased (0.105645 --> 0.105559).  Saving best model ...
6m 40s
Epoch 29/200
----------
LR 0.001
train: bce: 0.010848, dice_loss: 0.095339, loss: 0.106187
val: bce: 0.009658, dice_loss: 0.096645, loss: 0.106303
EarlyStopping counter: 1 out of 30
6m 34s
Epoch 30/200
----------
LR 0.001
train: bce: 0.010753, dice_loss: 0.095358, loss: 0.106110
val: bce: 0.011209, dice_loss: 0.094477, loss: 0.105686
EarlyStopping counter: 2 out of 30
6m 36s
Epoch 31/200
----------
LR 0.001
train: bce: 0.010660, dice_loss: 0.095339, loss: 0.105999
val: bce: 0.010185, dice_loss: 0.095043, loss: 0.105228
Validation loss decreased (0.105559 --> 0.105228).  Saving best model ...
6m 39s
Epoch 32/200
----------
LR 0.001
train: bce: 0.010523, dice_loss: 0.095333, loss: 0.105857
val: bce: 0.009360, dice_loss: 0.096426, loss: 0.105787
EarlyStopping counter: 1 out of 30
6m 29s
Epoch 33/200
----------
LR 0.001
train: bce: 0.010349, dice_loss: 0.095339, loss: 0.105688
val: bce: 0.009344, dice_loss: 0.096122, loss: 0.105466
EarlyStopping counter: 2 out of 30
6m 27s
Epoch 34/200
----------
LR 0.001
train: bce: 0.010289, dice_loss: 0.095345, loss: 0.105634
val: bce: 0.009390, dice_loss: 0.095703, loss: 0.105093
Validation loss decreased (0.105228 --> 0.105093).  Saving best model ...
6m 28s
Epoch 35/200
----------
LR 0.001
train: bce: 0.010113, dice_loss: 0.095336, loss: 0.105449
val: bce: 0.009545, dice_loss: 0.095285, loss: 0.104830
Validation loss decreased (0.105093 --> 0.104830).  Saving best model ...
6m 29s
Epoch 36/200
----------
LR 0.001
train: bce: 0.010000, dice_loss: 0.095350, loss: 0.105350
val: bce: 0.010922, dice_loss: 0.094427, loss: 0.105349
EarlyStopping counter: 1 out of 30
6m 37s
Epoch 37/200
----------
LR 0.001
train: bce: 0.009783, dice_loss: 0.095334, loss: 0.105117
val: bce: 0.009826, dice_loss: 0.094906, loss: 0.104732
Validation loss decreased (0.104830 --> 0.104732).  Saving best model ...
6m 39s
Epoch 38/200
----------
LR 0.001
train: bce: 0.009724, dice_loss: 0.095332, loss: 0.105056
val: bce: 0.009159, dice_loss: 0.095483, loss: 0.104642
Validation loss decreased (0.104732 --> 0.104642).  Saving best model ...
6m 41s
Epoch 39/200
----------
LR 0.001
train: bce: 0.009521, dice_loss: 0.095338, loss: 0.104859
val: bce: 0.009683, dice_loss: 0.094701, loss: 0.104384
Validation loss decreased (0.104642 --> 0.104384).  Saving best model ...
6m 43s
Epoch 40/200
----------
LR 0.001
train: bce: 0.009482, dice_loss: 0.095347, loss: 0.104829
val: bce: 0.008801, dice_loss: 0.095693, loss: 0.104494
EarlyStopping counter: 1 out of 30
6m 42s
Epoch 41/200
----------
LR 0.001
train: bce: 0.009384, dice_loss: 0.095336, loss: 0.104721
val: bce: 0.009706, dice_loss: 0.094803, loss: 0.104509
EarlyStopping counter: 2 out of 30
6m 37s
Epoch 42/200
----------
LR 0.001
train: bce: 0.009303, dice_loss: 0.095348, loss: 0.104651
val: bce: 0.009281, dice_loss: 0.094840, loss: 0.104121
Validation loss decreased (0.104384 --> 0.104121).  Saving best model ...
6m 44s
Epoch 43/200
----------
LR 0.001
train: bce: 0.009218, dice_loss: 0.095341, loss: 0.104559
val: bce: 0.009005, dice_loss: 0.095030, loss: 0.104034
Validation loss decreased (0.104121 --> 0.104034).  Saving best model ...
6m 36s
Epoch 44/200
----------
LR 0.001
train: bce: 0.009119, dice_loss: 0.095363, loss: 0.104482
val: bce: 0.009153, dice_loss: 0.094825, loss: 0.103978
Validation loss decreased (0.104034 --> 0.103978).  Saving best model ...
6m 43s
Epoch 45/200
----------
LR 0.001
train: bce: 0.008990, dice_loss: 0.095351, loss: 0.104341
val: bce: 0.008259, dice_loss: 0.096127, loss: 0.104385
EarlyStopping counter: 1 out of 30
6m 31s
Epoch 46/200
----------
LR 0.001
train: bce: 0.008902, dice_loss: 0.095349, loss: 0.104251
val: bce: 0.008488, dice_loss: 0.095400, loss: 0.103889
Validation loss decreased (0.103978 --> 0.103889).  Saving best model ...
6m 30s
Epoch 47/200
----------
LR 0.001
train: bce: 0.008938, dice_loss: 0.095348, loss: 0.104287
val: bce: 0.008974, dice_loss: 0.095064, loss: 0.104038
EarlyStopping counter: 1 out of 30
6m 28s
Epoch 48/200
----------
LR 0.001
train: bce: 0.008782, dice_loss: 0.095337, loss: 0.104119
val: bce: 0.009022, dice_loss: 0.094977, loss: 0.104000
EarlyStopping counter: 2 out of 30
6m 28s
Epoch 49/200
----------
LR 0.001
train: bce: 0.008659, dice_loss: 0.095304, loss: 0.103963
val: bce: 0.009227, dice_loss: 0.096307, loss: 0.105534
EarlyStopping counter: 3 out of 30
6m 28s
Epoch 50/200
----------
LR 0.001
train: bce: 0.008869, dice_loss: 0.095367, loss: 0.104236
val: bce: 0.008323, dice_loss: 0.095391, loss: 0.103714
Validation loss decreased (0.103889 --> 0.103714).  Saving best model ...
6m 40s
Epoch 51/200
----------
LR 0.001
train: bce: 0.008684, dice_loss: 0.095337, loss: 0.104021
val: bce: 0.007273, dice_loss: 0.099747, loss: 0.107021
EarlyStopping counter: 1 out of 30
6m 41s
Epoch 52/200
----------
LR 0.001
train: bce: 0.008919, dice_loss: 0.095377, loss: 0.104296
val: bce: 0.007448, dice_loss: 0.097125, loss: 0.104573
EarlyStopping counter: 2 out of 30
6m 39s
Epoch 53/200
----------
LR 0.001
train: bce: 0.008883, dice_loss: 0.095391, loss: 0.104274
val: bce: 0.008206, dice_loss: 0.095692, loss: 0.103898
EarlyStopping counter: 3 out of 30
6m 40s
Epoch 54/200
----------
LR 0.001
train: bce: 0.009051, dice_loss: 0.095360, loss: 0.104412
val: bce: 0.009856, dice_loss: 0.094522, loss: 0.104379
EarlyStopping counter: 4 out of 30
6m 41s
Epoch 55/200
----------
LR 0.001
train: bce: 0.008605, dice_loss: 0.095336, loss: 0.103941
val: bce: 0.007668, dice_loss: 0.096019, loss: 0.103688
Validation loss decreased (0.103714 --> 0.103688).  Saving best model ...
6m 39s
Epoch 56/200
----------
LR 0.001
train: bce: 0.008653, dice_loss: 0.095366, loss: 0.104019
val: bce: 0.009427, dice_loss: 0.094426, loss: 0.103853
EarlyStopping counter: 1 out of 30
6m 54s
Epoch 57/200
----------
LR 0.001
train: bce: 0.010297, dice_loss: 0.095319, loss: 0.105617
val: bce: 0.008324, dice_loss: 0.095224, loss: 0.103548
Validation loss decreased (0.103688 --> 0.103548).  Saving best model ...
6m 57s
Epoch 58/200
----------
LR 0.001
train: bce: 0.009105, dice_loss: 0.095453, loss: 0.104559
val: bce: 0.011567, dice_loss: 0.094956, loss: 0.106523
EarlyStopping counter: 1 out of 30
6m 54s
Epoch 59/200
----------
LR 0.001
train: bce: 0.008783, dice_loss: 0.095336, loss: 0.104119
val: bce: 0.007603, dice_loss: 0.095640, loss: 0.103243
Validation loss decreased (0.103548 --> 0.103243).  Saving best model ...
6m 54s
Epoch 60/200
----------
LR 0.001
train: bce: 0.008708, dice_loss: 0.095304, loss: 0.104012
val: bce: 0.007696, dice_loss: 0.094448, loss: 0.102144
Validation loss decreased (0.103243 --> 0.102144).  Saving best model ...
6m 55s
Epoch 61/200
----------
LR 0.001
train: bce: 0.009668, dice_loss: 0.095392, loss: 0.105060
val: bce: 0.009184, dice_loss: 0.094842, loss: 0.104025
EarlyStopping counter: 1 out of 30
6m 47s
Epoch 62/200
----------
LR 0.001
train: bce: 0.008946, dice_loss: 0.095320, loss: 0.104266
val: bce: 0.007478, dice_loss: 0.097699, loss: 0.105176
EarlyStopping counter: 2 out of 30
6m 28s
Epoch 63/200
----------
LR 0.001
train: bce: 0.009368, dice_loss: 0.095383, loss: 0.104751
val: bce: 0.008322, dice_loss: 0.096188, loss: 0.104510
EarlyStopping counter: 3 out of 30
6m 27s
Epoch 64/200
----------
LR 0.001
train: bce: 0.009141, dice_loss: 0.094950, loss: 0.104091
val: bce: 0.008968, dice_loss: 0.096886, loss: 0.105854
EarlyStopping counter: 4 out of 30
6m 28s
Epoch 65/200
----------
LR 0.001
train: bce: 0.009543, dice_loss: 0.095176, loss: 0.104718
val: bce: 0.017374, dice_loss: 0.094267, loss: 0.111642
EarlyStopping counter: 5 out of 30
6m 27s
Epoch 66/200
----------
LR 0.001
train: bce: 0.010186, dice_loss: 0.095390, loss: 0.105575
val: bce: 0.009150, dice_loss: 0.094996, loss: 0.104146
EarlyStopping counter: 6 out of 30
6m 27s
Epoch 67/200
----------
LR 0.001
train: bce: 0.009507, dice_loss: 0.095062, loss: 0.104568
val: bce: 0.017471, dice_loss: 0.094381, loss: 0.111851
EarlyStopping counter: 7 out of 30
6m 27s
Epoch 68/200
----------
LR 0.001
train: bce: 0.009996, dice_loss: 0.094899, loss: 0.104895
val: bce: 0.009764, dice_loss: 0.096279, loss: 0.106043
EarlyStopping counter: 8 out of 30
6m 27s
Epoch 69/200
----------
LR 0.001
train: bce: 0.009924, dice_loss: 0.095068, loss: 0.104992
val: bce: 0.009252, dice_loss: 0.095246, loss: 0.104498
EarlyStopping counter: 9 out of 30
6m 28s
Epoch 70/200
----------
LR 0.001
train: bce: 0.010140, dice_loss: 0.095322, loss: 0.105462
val: bce: 0.008746, dice_loss: 0.094189, loss: 0.102934
EarlyStopping counter: 10 out of 30
6m 28s
Epoch 71/200
----------
LR 0.001
train: bce: 0.009779, dice_loss: 0.095169, loss: 0.104948
val: bce: 0.009004, dice_loss: 0.093808, loss: 0.102812
EarlyStopping counter: 11 out of 30
6m 27s
Epoch 72/200
----------
LR 0.0001
train: bce: 0.007951, dice_loss: 0.093153, loss: 0.101104
val: bce: 0.007350, dice_loss: 0.094731, loss: 0.102081
Validation loss decreased (0.102144 --> 0.102081).  Saving best model ...
6m 28s
Epoch 73/200
----------
LR 0.0001
train: bce: 0.007200, dice_loss: 0.092109, loss: 0.099309
val: bce: 0.007880, dice_loss: 0.094669, loss: 0.102549
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 74/200
----------
LR 0.0001
train: bce: 0.006930, dice_loss: 0.090049, loss: 0.096979
val: bce: 0.007647, dice_loss: 0.092321, loss: 0.099968
Validation loss decreased (0.102081 --> 0.099968).  Saving best model ...
6m 28s
Epoch 75/200
----------
LR 0.0001
train: bce: 0.006475, dice_loss: 0.089441, loss: 0.095916
val: bce: 0.008849, dice_loss: 0.091784, loss: 0.100633
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 76/200
----------
LR 0.0001
train: bce: 0.006605, dice_loss: 0.088488, loss: 0.095093
val: bce: 0.007381, dice_loss: 0.093694, loss: 0.101075
EarlyStopping counter: 2 out of 30
6m 29s
Epoch 77/200
----------
LR 0.0001
train: bce: 0.006505, dice_loss: 0.088979, loss: 0.095484
val: bce: 0.007053, dice_loss: 0.094406, loss: 0.101459
EarlyStopping counter: 3 out of 30
6m 30s
Epoch 78/200
----------
LR 0.0001
train: bce: 0.006311, dice_loss: 0.088159, loss: 0.094470
val: bce: 0.008111, dice_loss: 0.089803, loss: 0.097914
Validation loss decreased (0.099968 --> 0.097914).  Saving best model ...
6m 28s
Epoch 79/200
----------
LR 0.0001
train: bce: 0.006309, dice_loss: 0.087738, loss: 0.094047
val: bce: 0.006441, dice_loss: 0.096214, loss: 0.102655
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 80/200
----------
LR 0.0001
train: bce: 0.006374, dice_loss: 0.087672, loss: 0.094046
val: bce: 0.006796, dice_loss: 0.091282, loss: 0.098078
EarlyStopping counter: 2 out of 30
6m 28s
Epoch 81/200
----------
LR 0.0001
train: bce: 0.006250, dice_loss: 0.087787, loss: 0.094037
val: bce: 0.007559, dice_loss: 0.092047, loss: 0.099606
EarlyStopping counter: 3 out of 30
6m 27s
Epoch 82/200
----------
LR 0.0001
train: bce: 0.006106, dice_loss: 0.087170, loss: 0.093276
val: bce: 0.006790, dice_loss: 0.102544, loss: 0.109334
EarlyStopping counter: 4 out of 30
6m 27s
Epoch 83/200
----------
LR 0.0001
train: bce: 0.006194, dice_loss: 0.086600, loss: 0.092793
val: bce: 0.006723, dice_loss: 0.093340, loss: 0.100063
EarlyStopping counter: 5 out of 30
6m 41s
Epoch 84/200
----------
LR 0.0001
train: bce: 0.005833, dice_loss: 0.085145, loss: 0.090978
val: bce: 0.006371, dice_loss: 0.095717, loss: 0.102088
EarlyStopping counter: 6 out of 30
6m 34s
Epoch 85/200
----------
LR 0.0001
train: bce: 0.006162, dice_loss: 0.085811, loss: 0.091973
val: bce: 0.006101, dice_loss: 0.099818, loss: 0.105919
EarlyStopping counter: 7 out of 30
6m 35s
Epoch 86/200
----------
LR 0.0001
train: bce: 0.006272, dice_loss: 0.086221, loss: 0.092492
val: bce: 0.007349, dice_loss: 0.092566, loss: 0.099916
EarlyStopping counter: 8 out of 30
6m 42s
Epoch 87/200
----------
LR 0.0001
train: bce: 0.005755, dice_loss: 0.085416, loss: 0.091171
val: bce: 0.006548, dice_loss: 0.095685, loss: 0.102233
EarlyStopping counter: 9 out of 30
6m 40s
Epoch 88/200
----------
LR 0.0001
train: bce: 0.005868, dice_loss: 0.085481, loss: 0.091350
val: bce: 0.005950, dice_loss: 0.093467, loss: 0.099417
EarlyStopping counter: 10 out of 30
6m 38s
Epoch 89/200
----------
LR 0.0001
train: bce: 0.005674, dice_loss: 0.085237, loss: 0.090911
val: bce: 0.005705, dice_loss: 0.099932, loss: 0.105637
EarlyStopping counter: 11 out of 30
6m 44s
Epoch 90/200
----------
LR 1e-05
train: bce: 0.005222, dice_loss: 0.083576, loss: 0.088798
val: bce: 0.006441, dice_loss: 0.091971, loss: 0.098412
EarlyStopping counter: 12 out of 30
6m 34s
Epoch 91/200
----------
LR 1e-05
train: bce: 0.005045, dice_loss: 0.082331, loss: 0.087376
val: bce: 0.005988, dice_loss: 0.089528, loss: 0.095515
Validation loss decreased (0.097914 --> 0.095515).  Saving best model ...
6m 28s
Epoch 92/200
----------
LR 1e-05
train: bce: 0.005062, dice_loss: 0.082645, loss: 0.087707
val: bce: 0.006239, dice_loss: 0.091719, loss: 0.097959
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 93/200
----------
LR 1e-05
train: bce: 0.005049, dice_loss: 0.081595, loss: 0.086644
val: bce: 0.006285, dice_loss: 0.091103, loss: 0.097387
EarlyStopping counter: 2 out of 30
6m 27s
Epoch 94/200
----------
LR 1e-05
train: bce: 0.005077, dice_loss: 0.082266, loss: 0.087343
val: bce: 0.005842, dice_loss: 0.090512, loss: 0.096354
EarlyStopping counter: 3 out of 30
6m 32s
Epoch 95/200
----------
LR 1e-05
train: bce: 0.005009, dice_loss: 0.082855, loss: 0.087864
val: bce: 0.006410, dice_loss: 0.089841, loss: 0.096251
EarlyStopping counter: 4 out of 30
6m 27s
Epoch 96/200
----------
LR 1e-05
train: bce: 0.004952, dice_loss: 0.081823, loss: 0.086775
val: bce: 0.006327, dice_loss: 0.090675, loss: 0.097002
EarlyStopping counter: 5 out of 30
6m 27s
Epoch 97/200
----------
LR 1e-05
train: bce: 0.004914, dice_loss: 0.081638, loss: 0.086552
val: bce: 0.006053, dice_loss: 0.090393, loss: 0.096446
EarlyStopping counter: 6 out of 30
6m 29s
Epoch 98/200
----------
LR 1e-05
train: bce: 0.004981, dice_loss: 0.081979, loss: 0.086959
val: bce: 0.006289, dice_loss: 0.088671, loss: 0.094960
Validation loss decreased (0.095515 --> 0.094960).  Saving best model ...
6m 28s
Epoch 99/200
----------
LR 1e-05
train: bce: 0.004925, dice_loss: 0.081847, loss: 0.086772
val: bce: 0.006220, dice_loss: 0.089634, loss: 0.095854
EarlyStopping counter: 1 out of 30
6m 27s
Epoch 100/200
----------
LR 1e-05
train: bce: 0.004881, dice_loss: 0.082137, loss: 0.087018
val: bce: 0.005910, dice_loss: 0.087609, loss: 0.093519
Validation loss decreased (0.094960 --> 0.093519).  Saving best model ...
6m 27s
Epoch 101/200
----------
LR 1e-05
train: bce: 0.004832, dice_loss: 0.081255, loss: 0.086086
val: bce: 0.006011, dice_loss: 0.088697, loss: 0.094709
EarlyStopping counter: 1 out of 30
6m 29s
Epoch 102/200
----------
LR 1e-05
train: bce: 0.004810, dice_loss: 0.081169, loss: 0.085979
val: bce: 0.006102, dice_loss: 0.089778, loss: 0.095880
EarlyStopping counter: 2 out of 30
6m 36s
Epoch 103/200
----------
LR 1e-05
train: bce: 0.004771, dice_loss: 0.081750, loss: 0.086521
val: bce: 0.005836, dice_loss: 0.091712, loss: 0.097548
EarlyStopping counter: 3 out of 30
6m 27s
Epoch 104/200
----------
LR 1e-05
train: bce: 0.004748, dice_loss: 0.080588, loss: 0.085336
val: bce: 0.005925, dice_loss: 0.090263, loss: 0.096188
EarlyStopping counter: 4 out of 30
6m 32s
Epoch 105/200
----------
LR 1e-05
train: bce: 0.004707, dice_loss: 0.080617, loss: 0.085324
val: bce: 0.005924, dice_loss: 0.089988, loss: 0.095912
EarlyStopping counter: 5 out of 30
6m 27s
Epoch 106/200
----------
LR 1e-05
train: bce: 0.004783, dice_loss: 0.081276, loss: 0.086059
val: bce: 0.006123, dice_loss: 0.090955, loss: 0.097079
EarlyStopping counter: 6 out of 30
6m 27s
Epoch 107/200
----------
LR 1e-05
train: bce: 0.004666, dice_loss: 0.080210, loss: 0.084876
val: bce: 0.005932, dice_loss: 0.089334, loss: 0.095266
EarlyStopping counter: 7 out of 30
6m 27s
Epoch 108/200
----------
LR 1e-05
train: bce: 0.004744, dice_loss: 0.081214, loss: 0.085958
val: bce: 0.006012, dice_loss: 0.091340, loss: 0.097351
EarlyStopping counter: 8 out of 30
6m 27s
Epoch 109/200
----------
LR 1e-05
train: bce: 0.004737, dice_loss: 0.080508, loss: 0.085245
val: bce: 0.006237, dice_loss: 0.090282, loss: 0.096518
EarlyStopping counter: 9 out of 30
6m 27s
Epoch 110/200
----------
LR 1e-05
train: bce: 0.004866, dice_loss: 0.080623, loss: 0.085489
val: bce: 0.005899, dice_loss: 0.091770, loss: 0.097670
EarlyStopping counter: 10 out of 30
6m 27s
Epoch 111/200
----------
LR 1e-05
train: bce: 0.004711, dice_loss: 0.080110, loss: 0.084821
val: bce: 0.005999, dice_loss: 0.089757, loss: 0.095756
EarlyStopping counter: 11 out of 30
6m 27s
Epoch 112/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004726, dice_loss: 0.080086, loss: 0.084812
val: bce: 0.006153, dice_loss: 0.091049, loss: 0.097202
EarlyStopping counter: 12 out of 30
6m 28s
Epoch 113/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004762, dice_loss: 0.080153, loss: 0.084915
val: bce: 0.006134, dice_loss: 0.090733, loss: 0.096867
EarlyStopping counter: 13 out of 30
6m 27s
Epoch 114/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004688, dice_loss: 0.080289, loss: 0.084977
val: bce: 0.006038, dice_loss: 0.089663, loss: 0.095702
EarlyStopping counter: 14 out of 30
6m 27s
Epoch 115/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004678, dice_loss: 0.079553, loss: 0.084231
val: bce: 0.005890, dice_loss: 0.089849, loss: 0.095740
EarlyStopping counter: 15 out of 30
6m 27s
Epoch 116/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004688, dice_loss: 0.080752, loss: 0.085440
val: bce: 0.005916, dice_loss: 0.090385, loss: 0.096301
EarlyStopping counter: 16 out of 30
6m 27s
Epoch 117/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004606, dice_loss: 0.079529, loss: 0.084134
val: bce: 0.005949, dice_loss: 0.088028, loss: 0.093976
EarlyStopping counter: 17 out of 30
6m 27s
Epoch 118/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004589, dice_loss: 0.080188, loss: 0.084777
val: bce: 0.005883, dice_loss: 0.090020, loss: 0.095903
EarlyStopping counter: 18 out of 30
6m 27s
Epoch 119/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004703, dice_loss: 0.080200, loss: 0.084903
val: bce: 0.005920, dice_loss: 0.090287, loss: 0.096207
EarlyStopping counter: 19 out of 30
6m 27s
Epoch 120/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004609, dice_loss: 0.080172, loss: 0.084781
val: bce: 0.005814, dice_loss: 0.088204, loss: 0.094017
EarlyStopping counter: 20 out of 30
6m 27s
Epoch 121/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004642, dice_loss: 0.079436, loss: 0.084078
val: bce: 0.005822, dice_loss: 0.091382, loss: 0.097204
EarlyStopping counter: 21 out of 30
6m 27s
Epoch 122/200
----------
LR 1.0000000000000002e-06
train: bce: 0.004621, dice_loss: 0.080044, loss: 0.084665
val: bce: 0.005787, dice_loss: 0.088197, loss: 0.093984
EarlyStopping counter: 22 out of 30
6m 27s
Epoch 123/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004572, dice_loss: 0.079810, loss: 0.084381
val: bce: 0.005747, dice_loss: 0.090431, loss: 0.096178
EarlyStopping counter: 23 out of 30
6m 26s
Epoch 124/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004602, dice_loss: 0.079429, loss: 0.084031
val: bce: 0.005692, dice_loss: 0.088859, loss: 0.094551
EarlyStopping counter: 24 out of 30
6m 27s
Epoch 125/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004586, dice_loss: 0.080322, loss: 0.084908
val: bce: 0.005780, dice_loss: 0.088655, loss: 0.094435
EarlyStopping counter: 25 out of 30
6m 26s
Epoch 126/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004610, dice_loss: 0.079362, loss: 0.083972
val: bce: 0.005802, dice_loss: 0.088594, loss: 0.094397
EarlyStopping counter: 26 out of 30
6m 26s
Epoch 127/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004635, dice_loss: 0.079554, loss: 0.084189
val: bce: 0.006083, dice_loss: 0.090991, loss: 0.097075
EarlyStopping counter: 27 out of 30
6m 26s
Epoch 128/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004632, dice_loss: 0.080823, loss: 0.085455
val: bce: 0.005939, dice_loss: 0.090257, loss: 0.096197
EarlyStopping counter: 28 out of 30
6m 26s
Epoch 129/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004626, dice_loss: 0.079512, loss: 0.084138
val: bce: 0.005852, dice_loss: 0.090786, loss: 0.096638
EarlyStopping counter: 29 out of 30
6m 26s
Epoch 130/200
----------
LR 1.0000000000000002e-07
train: bce: 0.004628, dice_loss: 0.079895, loss: 0.084523
val: bce: 0.006043, dice_loss: 0.088377, loss: 0.094420
EarlyStopping counter: 30 out of 30
6m 26s
Early stopping after epoch 129
Best val loss: 0.093519
----------------------------------------------------------------
The number of test set: 1348
----------------------------------------------------------------
----------
The Evaluation Starts ...
----------
The total samples: 1348
The average dice score is 0.9078090190887451.
The number of cancer samples: 125
The average dice score of the slices which have cancer is 0.005812449846416712.
The number of correct cases when the prediction predicts some poriton of the cancer: 0
The number of incorrect cases when the prediction predicts some poriton of the cancer: 0
The number of cases when the prediction predicts no cancer but it has cancer: 125
The number of non-cancer samples: 1223
The average dice score of the slices which have non-cancer is 1.0.
The number of cases when the prediction predicts no cancer when it has no cancer: 1223
The number of cases when the prediction predicts cancer when it has no cancer: 0
0m 32s
